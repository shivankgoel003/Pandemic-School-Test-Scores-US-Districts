---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: LINK."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse) # a collection of data-related packages
library(knitr) # for kable
library(kableExtra)
library(here)
library(ggbeeswarm)
library(ggplot2)


#reading cleaned data

state_score = read_csv(file = here("outputs/data/cleaned_state_scoredata.csv"),       
  show_col_types = FALSE
)

head(state_score)

rhode = read_csv(
  file = here("outputs/data/cleaned_learningmodel/rhode.csv"),       
  show_col_types = FALSE
)

colorado = read_csv(
  file = here("outputs/data/cleaned_learningmodel/colorado.csv"),       
  show_col_types = FALSE
)

connecticut = read_csv(
  file = here("outputs/data/cleaned_learningmodel/connecticut.csv"),       
  show_col_types = FALSE
)

massachusets = read_csv(
  file = here("outputs/data/cleaned_learningmodel/massachusets.csv"),       
  show_col_types = FALSE
)
minnesota = read_csv(
  file = here("outputs/data/cleaned_learningmodel/minnesota.csv"),       
  show_col_types = FALSE
)

mississippi = read_csv(
  file = here("outputs/data/cleaned_learningmodel/mississippi.csv"),       
  show_col_types = FALSE
)

ohio = read_csv(
  file = here("outputs/data/cleaned_learningmodel/ohio.csv"),       
  show_col_types = FALSE
)
virginia = read_csv(
  file = here("outputs/data/cleaned_learningmodel/virginia.csv"),       
  show_col_types = FALSE
)
westvirginia = read_csv(
  file = here("outputs/data/cleaned_learningmodel/westvirginia.csv"),       
  show_col_types = FALSE
)
winscosin = read_csv(
  file = here("outputs/data/cleaned_learningmodel/winscosin.csv"),       
  show_col_types = FALSE
)

wyoming = read_csv(
  file = here("outputs/data/cleaned_learningmodel/wyoming.csv"),       
  show_col_types = FALSE
)

```


# Introduction

The COVID-19 pandemic has profoundly disrupted education systems worldwide, compelling schools and districts across the United States to rapidly adapt their learning models. In 2020 and 2021, educational institutions faced unprecedented challenges, transitioning between in-person, hybrid, and virtual learning models in response to evolving public health guidelines and infection rates. This shift has brought into sharp focus the need to understand the implications of these various schooling models on educational outcomes.

This paper delves into a comprehensive analysis across 11 U.S. states, examining the relationship between different schooling models and their impact on student enrollment and staffing patterns. The unique dataset compiled for this study encompasses a variety of metrics, including total enrollment, in-person and virtual attendance, as well as staff count across different learning models. By analyzing data from kindergarten to 12th grade, this study provides a granular view of how the pandemic has reshaped the educational landscape across these states.

Our findings reveal significant variations in how states have navigated the challenges posed by the pandemic, with notable differences in the adoption of in-person, hybrid, and virtual learning models. We observe that these variations are not only reflective of public health policies but also indicate broader socio-economic and demographic influences. For instance, preliminary analysis suggests that shifts to virtual learning correlate with changes in student enrollment, raising questions about equity and access in education during these challenging times.

The remainder of the paper is structured as follows: Section 2 provides a detailed overview of the data and methodology employed in this study. Section 3 presents an in-depth analysis of the schooling models across the 11 states, offering insights into the trends and patterns observed in the data. Section 4 discusses the key findings, exploring the implications of these schooling models on educational outcomes. Finally, Section 5 concludes with a reflection on the study's findings, limitations, and potential directions for future research in this critical area of educational policy.

The remainder of this paper is structured as follows. @sec-data....



# Data {#sec-data}

## Data Source and Collection

The data utilized in this study is obtained from the compilation of district-level schooling models and state standardized assessment data, originally featured in the paper "Pandemic Schooling Mode and Student Test Scores: Evidence from US School Districts" [@citepaper] published in the American Economic Review: Insights in June 2023. [@citewebsite]. The primary dataset encompasses schooling mode data from the 2020–2021 academic year across 11 U.S. states, integrating various educational approaches during the pandemic, including in-person, hybrid, and virtual learning environments. These datasets were sourced from COVID-19 School Data Hub [@citedata], district-level state standardized assessment data from spring
2016–2019 and 2021, and additional data demographic statistics from the National Center for Education Statistics (NCES) to establish a comprehensive analytical framework. We also used additional year 2020 household data by Household Pulse Survey [@citehousehold] from  U.S. Census Bureau spanning weeks 1 to 12.

Our analyses incorporate three categories of data: district-level schooling modes, state standardized assessment results from the academic years 2016–2019 and 2021, and auxiliary  that encompass district demographics and county-level variables. The following subsections detail the sources, collection methodologies, and data cleaning procedures undertaken to ensure the accuracy and reliability of the datasets for our analysis.  

**State Score Data**: This dataset encompasses state-level academic performance statistics from 2016 to 2020. Variables include the proportion of in-person, virtual, and hybrid learning, participation rates, standardized test pass rates, COVID-19 case rates per 100,000 in school zip codes, peak monthly cases, total enrollment figures, and political voting shares by district.

**Learning Model Data**: This dataset details the learning models adopted by school districts in Colorado, Connecticut, Ohio, Virginia, West Virginia, Wyoming, Mississippi, Rhode Island, Minnesota, Massachusetts, and Wisconsin. Each state's data outlines the specific learning model (in-person, virtual, hybrid) employed over time, enrollment figures, and staffing counts.

## Data Cleaning and Processing
We used R [@citeR] for data cleaning and processing, utilizing packages like tidyverse [@tidyverse] for data manipulation and janitor [@citejan] for cleaning column names. The cleaning process involved standardizing learning model categories, selecting columns of interest, and simplifying data for analysis. We integrated data from different states, and made sure that variations in reporting and measurement were addressed while combining them into one. For instance, some states categorized their schooling mode as "In-person," while others used "In-Person." To ensure they are equivalent, we standardized these terms. We also conducted a check for missing data values, and imputed or excluded them as appropriate based on the context. The variables were also renamed for clarity and consistency across different states' datasets.  A sample of cleaned state score data can be seen in [@tbl_cleaned_data].

```{r tbl_cleaned_data}
#| message: false
#| echo: false
#| warning: false
#| tbl-cap: Sample of Cleaned State Score Data
#| label: tbl_cleaned_data

library(kableExtra)
library(knitr)

options(kableExtra.latex.max.width=1)
head(state_score, 6) |>
  kable(
        col.names = c("State", "Year", "Share In-person", "Share Virtual", "Share Hybrid", "Participation", "Pass Rate", "Covid cases rate per 100k", "Total Enrollment"),
    booktabs = TRUE,
    longtable = FALSE
  ) %>%
  kable_styling(latex_options = c("striped", "scale_down"), font_size = 6)
```


```{r}
#| label: fig-bills
#| fig-cap: Bills of penguins
#| echo: false
#| warning: false

library(dplyr)

# Assuming each state data frame has the same structure and columns
all_states <- bind_rows(
  colorado %>% mutate(state = "Colprado"),
  connecticut %>% mutate(state = "Connecticut"),
  massachusets %>% mutate(state = "Massachusets"),
  minnesota %>% mutate(state = "Minnesota"),
  mississippi %>% mutate(state = "Mississsippi"),
  ohio %>% mutate(state = "Ohio"),
  rhode %>% mutate(state = "Rhode Islands"),
  virginia %>% mutate(state = "Virginia"),
  westvirginia %>% mutate(state = "West Virginia"),
  winscosin %>% mutate(state = "Winscosin"),
  wyoming %>% mutate(state = "Wyoming"),
  
)

state_score <- na.omit(state_score)

#therefore we scale it first, by taking proportions:
state_totals <- all_states %>%
  group_by(state) %>%
  summarise(total = n())

# Calculate the proportion of each learning model within each state
all_states <- all_states %>%
  group_by(state, learning_model) %>%
  summarise(count = n(), .groups = 'drop') %>%
  left_join(state_totals, by = "state") %>%
  mutate(proportion = count / total)

# Plotting with a bar graph
# ggplot(all_states, aes(x = state, y = proportion, fill = learning_model)) + 
#   geom_bar(stat = "identity", position = "dodge") +
#   theme_minimal() +
#   labs(x = "State", y = "Proportion", fill = "Learning Model", 
#        title = "Proportional Comparison of Learning Models in US States") +
  # scale_y_continuous(labels = scales::percent)

ggplot(all_states, aes(x = state, y = proportion, fill = learning_model)) + 
  geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +
  theme_minimal() +
  labs(x = "State", y = "Proportion of Leaning Models", fill = "Learning Model", 
       title = "Proportional Comparison of Learning Models in US States") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 8),
        plot.title = element_text(hjust = 0.5))

ggplot(state_score, aes(x = case_rate_per100k_zip, y = pass)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "COVID-19 Case Rate per 100k", y = "Passing Rate", 
       title = "Correlation between Passing Rate and COVID-19 Case Rate per 100k") +
  theme_minimal() +
  xlim(0, 350)


ggplot(state_score, aes(x = case_rate_per100k_zip, y = pass)) +
  geom_point() +  # Add points
  geom_smooth(method = "lm", se = FALSE) +  # Add a linear regression line without standard error bands
  labs(x = "COVID-19 Case Rate per 100k", y = "Passing Rate", 
       title = "Correlation between Passing Rate and COVID-19 Case Rate per 100k") +
  theme_minimal()
# Print the results of the correlation test




# Create a box plot
state_score <- state_score %>% 
  filter(!is.na(case_rate_per100k_zip) & !is.nan(case_rate_per100k_zip))

state_score$category <- cut(state_score$case_rate_per100k_zip, 
                            breaks = quantile(state_score$case_rate_per100k_zip, 
                                              probs = 0:3/3, na.rm = TRUE), 
                            include.lowest = TRUE, 
                            labels = c("Low", "Medium", "High"))

# Create a box plot with colors
ggplot(state_score, aes(x = category, y = pass, fill = category)) +
  geom_boxplot() +
  labs(title = "Box Plot of Passing Rates by COVID-19 Case Rate Categories", 
       x = "COVID-19 Case Rate Category", 
       y = "Passing Rate") +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel1") 





ggplot(state_score, aes(x = pass)) +
  geom_density(fill = "blue", alpha = 0.5) +
  labs(title = "Density Plot of Passing Rates", x = "Passing Rate", y = "Density") +
  theme_minimal()


```
## Data Modifications

In this study, we created a new dataset by carefully selecting and combining data from the Household Pulse Survey, available from the U.S. Census Bureau for weeks 1 to 12. This process involved choosing key variables that were crucial for our research. We aimed to analyze the connection between economic changes, particularly the loss of employment income, and their impact on educational outcomes, focusing specifically on school passing rates. This helped us to understand the relationship between these economic factors and educational performance. To ensure consistency, we standardized terminologies and measurements, and aligned variables such as timeframes and demographic categories across the datasets. For example, we combined the state score data with the weekly household data, aligned variables relevant to our study. The merged data file was thereafter saved as a CSV file to study the trends later on.


# Results
In the Results section of our study, our analysis discusses two key geographical representations:

1. Passing Rate Trends Over Different Years and Subjects: Figue [@fig] shows the decline in passing rates in English Language Arts (ELA) and Mathematics from 2016 to 2021, depicting a consistent downward trend across both subjects especially during pandemic period from 2019 to 2021.

2. Variations in Passing Rates Between Different States: The box plot comparison [@fig2] across states showcases the wide range of passing rates, with some states showing a wide spread, which indicates the  variability in performance within those states.

Building on these overviews, we visualized the distribution of learning models across states using box plots. The box plot for in-person learning [@box_plot_inperson] revealed a range of engagement across states, with Virginia showing a median of 0 percentage in-person learning during 2019 to 2021, whereas Wyoming having a median of approximately 80 percent in-person learning. The virtual learning model box plot [@box_plot_virtual] showed a significant number of outliers, suggesting that certain states had districts with a notably high share of virtual learning.The states Wyoming and Rhode Island had a median of 0 percent virtual learning whereas Virginia had highest median of virtual learning.  Lastly, the hybrid learning model [@box_plot_hybrid] box plot displayed variability, with some states having a wide interquartile range, showing a diverse adoption of this learning model. However, Colorado had a median of 0 percent adoption of hybrid learning model relative to other states. These visual insights set the foundation for further statistical examination in subsequent analyses. 

Following the initial box plots, we continued our investigation with a scatter plot [@scatterplot] and examined the relationship between the share of virtual learning and student passing rates. The scatter plot indicates a downward trend, with a line suggesting that an increase in the share of virtual learning correlates with a decrease in passing rates. The data points suggest that higher virtual learning is associated with lower academic performance of students.

After the initial analysis of learning model, we further studied the impact of Covid-19 on student's learning. We again plotted box plots [@covidboxplot] to observe the relationship between COVID-19 case rates per 100,000 and passing rates. COVID-19 case rates per 100,000 were categorized into 'Low,' 'Medium,' and 'High' based on the data's quartile distribution. It is revealed from the plot that districts with 'Low' COVID-19 case rates showed a median passing rates near the 50th percentile, while those categorized as 'High' showed a decline in median passing rates. 

We further expanded our analysis to examine the relationship between the average number of students per staff and the average pass rate for virtual learners across the 11 states [@fig]. Due to insufficient data, Rhode Island (RI) and Mississippi (MS) were not graphed. The graph plots both these variables and shows an overall positive correlation between the number of students per staff on average vs the average pass rate. The trend indicates that the states with the higher pass rates also had more students assigned to a teacher. We note that Virginia (VA) had the highest student-to-staff ratio, while Wyoming (WY) had the lowest. While this may be not expected of a general learning environment, the virtual learning model may be a factor contributing to this positive relationship between the student-to-staff ratio and the average pass rates across the states. 

```{r}
#| label: box_plot_inperson
#| fig-cap: Relationship between wing length and width
#| echo: false
#| warning: false
#| message: false

library(dplyr)



data_2019 <- state_score %>%
  filter(year == 2019) %>%
  group_by(state) %>%
  summarise(
    avg_share_inperson = mean(share_inperson, na.rm = TRUE)*100,
    avg_share_virtual = mean(share_virtual, na.rm = TRUE)*100,
    avg_share_hybrid = mean(share_hybrid, na.rm = TRUE)*100,
    avg_participation = mean(participation, na.rm = TRUE),
    avg_pass_rate = mean(pass, na.rm = TRUE)*100
  )

data_2021 <- state_score %>%
  filter(year == 2021) %>%
  group_by(state) %>%
  summarise(
    avg_share_inperson = mean(share_inperson, na.rm = TRUE)*100,
    avg_share_virtual = mean(share_virtual, na.rm = TRUE)*100,
    avg_share_hybrid = mean(share_hybrid, na.rm = TRUE)*100,
    avg_participation = mean(participation, na.rm = TRUE),
    avg_pass_rate = mean(pass, na.rm = TRUE)*100
  )


options(kableExtra.latex.max.width = 1)
data_2019 %>% 
  kable(format = "markdown", 
        col.names = c("State", "Avg. Share In-person", "Avg. Share Virtual", "Avg. Share Hybrid", "Avg. Participation", "Avg. Pass Rate"),
        booktabs = TRUE,
        longtable = FALSE
  ) %>%
  kable_styling(latex_options = c("striped", "scale_down"), font_size = 9)

options(kableExtra.latex.max.width = 1)
data_2021 %>% 
  kable(format = "markdown", 
        col.names = c("State", "Avg. Share In-person", "Avg. Share Virtual", "Avg. Share Hybrid", "Avg. Participation", "Avg. Pass Rate"),
        booktabs = TRUE,
        longtable = FALSE
  ) %>%
  kable_styling(latex_options = c("striped", "scale_down"), font_size = 9)




inperson_data <- state_score %>%
  select(state, share_inperson)

# Step 2: Plot the data
ggplot(inperson_data, aes(x = state, y = share_inperson)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Box Plot of In-Person Learning Model Share Across States",
       x = "State", y = "Share of In-Person Learning") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

virtual_data <- state_score %>%
  select(state, share_virtual)

# Plot for virtual learning model
ggplot(virtual_data, aes(x = state, y = share_virtual)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Box Plot of Virtual Learning Model Share Across States",
       x = "State", y = "Share of Virtual Learning") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Prepare data for hybrid learning model
hybrid_data <- state_score %>%
  select(state, share_hybrid)

# Plot for hybrid learning model
ggplot(hybrid_data, aes(x = state, y = share_hybrid)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Box Plot of Hybrid Learning Model Share Across States",
       x = "State", y = "Share of Hybrid Learning") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(state_score, aes(x = share_virtual, y = pass)) +
  geom_point() +  # Add points to the plot
  geom_smooth(method = "lm", se = FALSE) +  # Add a linear trend line without the shaded confidence interval
  theme_minimal() +
  labs(title = "Scatter Plot of Virtual Learning Share vs. Passing Rate",
       x = "Share of Virtual Learning", y = "Passing Rate") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



state_with_highest_virtual <- state_score %>%
  group_by(state) %>%
  summarize(average_virtual = mean(share_virtual, na.rm = TRUE)) %>%
  arrange(desc(average_virtual)) %>%
  slice(1) %>%
  pull(state)

# Filter the data for the state with the highest virtual learning
state_passing_data <- state_score %>%
  filter(state == state_with_highest_virtual)

# Plot the passing rates against the case rate per 100k for the state with the highest virtual learning
ggplot(state_passing_data, aes(x = case_rate_per100k_zip, y = pass)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Add a linear trend line
  theme_minimal() +
  labs(title = paste("Passing Rate vs. Case Rate per 100k in", state_with_highest_virtual),
       x = "Case Rate per 100k", y = "Passing Rate") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))




state_with_highest_cases <- state_score %>%
  group_by(state) %>%
  summarize(average_cases = mean(case_rate_per100k_zip, na.rm = TRUE)) %>%
  arrange(desc(average_cases)) %>%
  slice(1) %>%
  pull(state)

# Filter the data for the state with the highest case rate per 100k
state_passing_data <- state_score %>%
  filter(state == state_with_highest_cases)

# Plot the passing rates for the state with the highest case rate per 100k
ggplot(state_passing_data, aes(x = as.factor(year), y = pass, group = state, color = state)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(title = paste("Passing Rate in", state_with_highest_cases, "with the Highest COVID-19 Case Rate"),
       x = "Year", y = "Passing Rate") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


# Find the state with the lowest case rate per 100k
state_with_lowest_cases <- state_score %>%
  group_by(state) %>%
  summarize(average_cases = mean(case_rate_per100k_zip, na.rm = TRUE)) %>%
  arrange(average_cases) %>%
  slice(1) %>%
  pull(state)

# Filter the data for the state with the lowest case rate per 100k
state_passing_data_lowest <- state_score %>%
  filter(state == state_with_lowest_cases)

# Plot the passing rates for the state with the lowest case rate per 100k
ggplot(state_passing_data_lowest, aes(x = as.factor(year), y = pass, group = state, color = state)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(title = paste("Passing Rate in", state_with_lowest_cases, "with the Lowest COVID-19 Case Rate"),
       x = "Year", y = "Passing Rate") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```



# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs,  instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.






# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details


# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 





\newpage


# References


